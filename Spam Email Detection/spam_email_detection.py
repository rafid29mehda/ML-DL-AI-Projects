# -*- coding: utf-8 -*-
"""Spam Email Detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yZDmLuL1iVQlO0lPSpEmAxOoVtwJsyB9

# Setup, Import Required Libraries and Load Data
"""

# Install necessary packages
!pip install nltk scikit-learn imbalanced-learn matplotlib seaborn

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from imblearn.over_sampling import SMOTE
import nltk
import string

# Download stopwords
nltk.download('stopwords')
nltk.download('wordnet')

# Load the new dataset
from google.colab import files
uploaded = files.upload()  # Upload your new dataset file here
new_df = pd.read_csv('spam_email.csv')  # Replace with actual file name

# Rename columns if needed
# Assuming the dataset has columns named 'Label' and 'text', rename as required
new_df.rename(columns={'Label': 'spam', 'text': 'text'}, inplace=True)

# Check dataset structure
print("Dataset Information:")
print(new_df.info())
print("First few rows:")
print(new_df.head())

"""# Preprocessing with Lemmatization"""

!pip install tqdm
from tqdm import tqdm


lemmatizer = WordNetLemmatizer()

# Wrap tqdm around the pandas apply function
tqdm.pandas()  # This enables tqdm to be used with Pandas

def clean_text(text):
    # Remove punctuation
    text = ''.join([char for char in text if char not in string.punctuation])
    # Tokenize and remove stopwords
    words = [word for word in text.split() if word.lower() not in stopwords.words('english')]
    # Lemmatize words
    words = [lemmatizer.lemmatize(word.lower()) for word in words]
    return ' '.join(words)

# Apply preprocessing with progress bar
new_df['cleaned_text'] = new_df['text'].progress_apply(clean_text)

"""# Vectorization with TF-IDF (Including Bi-grams and Tri-grams)

"""

# Rename the 'label' column to 'spam'
new_df.rename(columns={'label': 'spam'}, inplace=True)

# Check if renaming was successful
print("Updated column names:", new_df.columns)

# Proceed with vectorization and SMOTE
vectorizer = TfidfVectorizer(ngram_range=(1, 3))
X = vectorizer.fit_transform(new_df['cleaned_text'])
y = new_df['spam']

"""# Handling Class Imbalance with SMOTE"""

# Apply SMOTE to balance the classes
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)
print("Original dataset shape:", y.value_counts())
print("Resampled dataset shape:", np.bincount(y_resampled))

"""# Split Data and Train with Hyperparameter Tuning"""

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Hyperparameter tuning with GridSearchCV
parameters = {'alpha': [0.1, 0.5, 1.0]}
nb_classifier = MultinomialNB()
grid_search = GridSearchCV(nb_classifier, parameters, cv=5, scoring='recall')
grid_search.fit(X_train, y_train)
print("Best Parameters:", grid_search.best_params_)

# Train the model with the best parameters
best_nb = grid_search.best_estimator_
best_nb.fit(X_train, y_train)

"""# Evaluate the Model"""

# Predictions
y_pred = best_nb.predict(X_test)
y_prob = best_nb.predict_proba(X_test)[:,1]

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

# Classification Report
print("Classification Report:")
print(classification_report(y_test, y_pred))

# ROC Curve
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
plt.plot(fpr, tpr, label='Naive Bayes (SMOTE)')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='best')
plt.show()

# Calculate AUC Score
auc_score = roc_auc_score(y_test, y_prob)
print("AUC Score:", auc_score)

"""# Validating Model through Sample Mail"""

def preprocess_email(email_text):
    # Remove punctuation
    email_text = ''.join([char for char in email_text if char not in string.punctuation])
    # Tokenize and remove stopwords
    words = [word for word in email_text.split() if word.lower() not in stopwords.words('english')]
    # Lemmatize words
    words = [lemmatizer.lemmatize(word.lower()) for word in words]
    return ' '.join(words)

def predict_spam(email_text, model, vectorizer):
    # Preprocess the email
    cleaned_text = preprocess_email(email_text)
    # Transform the email text using the TF-IDF vectorizer
    email_features = vectorizer.transform([cleaned_text])
    # Predict using the trained model
    prediction = model.predict(email_features)
    # Return the result
    return 'Spam' if prediction == 1 else 'Ham'

# Example email text to classify
sample_email = "Congratulations! You've won a free ticket to the Bahamas. Click here to claim your prize."

# Call the prediction function with the trained model and TF-IDF vectorizer
result = predict_spam(sample_email, best_nb, vectorizer)
print(f"The email is classified as: {result}")